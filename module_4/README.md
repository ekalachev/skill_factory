![Title PNG "Skill Factory"](./assets/skillfactory_logo.png)

# SkillFactory_Projects
Projects for SkillFactory DST

# Project - Bank credit scoring
- Team: **[Anna Kostyakova](https://github.com/anna-kostyakova)**, **[Eldar Kalachev](https://github.com/ekalachev)**
- Team name on Kaggle.com - Team one
- **[Kaggle notebook](https://www.kaggle.com/ekalachev/bank-credit-scoring-team-one)**

### Public score on Kaggle.com - 0.73778

## Задание
Построение модели для прогнозирования вероятности дефолта заемщика.

### Описание признаков
- client_id - идентификатор клиента
- education - уровень образования
- sex - пол заемщика
- age - возраст заемщика
- car - флаг наличия автомобиля
- car_type - флаг автомобиля иномарки
- decline_app_cnt - количество отказанных прошлых заявок
- good_work - флаг наличия “хорошей” работы
- bki_request_cnt - количество запросов в БКИ
- home_address - категоризатор домашнего адреса
- work_address - категоризатор рабочего адреса
- income - доход заемщика
- foreign_passport - наличие загранпаспорта
- sna - связь заемщика с клиентами банка
- first_time - давность наличия информации о заемщике
- score_bki - скоринговый балл по данным из БКИ
- region_rating - рейтинг региона
- app_date - дата подачи заявки
- default - флаг дефолта по кредиту

### В результате работы над данными:
- был произведен разведывательный анализ данных
- была произведена очистка данных и отработка выбросов (в финальной версии удаление и сглаживание выбросов нет, так как это ухудшало качество модели, оставлено только логарифмирование и дополнительная помощь модели в виде преобразования признаков дополнительно в категориальные)
- созданы новые признаки
- отбраны признаки для модели по значимости
- произведена балансировка классов с помощью undersampling
- подобраны оптимальные гиперпараметры для модели
- проведена проверка модели на переобучение - результат отрицательный

#### Для улучшения качества модели были также использованы следующие инструменты:
- stratified shuffle split
- SelectKBest (f_classif, mutual_info_classif, chi2)
- SMOTE oversampling

В разных комбинациях данные инструменты улучшали показатели нашей модели. Особенно хорошие показатели были при использовании SMOTE. **Были достигнуты следующие показатели:**
- ROC AUC - 0.7552
- Balanced accuracy - 0.688
- F1-score - 0.692
- Precision score - 0.685
- Recall score - 0.699
- TP - 9013
- FP - 4148
- FN - 3881
- TN - 8729

Однако при использовании данной модели для submission на Kaggle.com соревновательная метрика была хуже, чем без SMOTE, stratified shuffle split & SelectKBest. Разница была в 1-2 сотые, и в рамках соревнования **было принято решение оставить лучший результат submission только на undersampling.**
Также можно обратить внимание, что в гиперпараметрах указан class_weight = 'balanced', что не является принципиальным, так как классы сбалансировали до запуска модели. Но добавление этого параметра все равно улучшает метрики (на тысячные доли). Поэтому в рамках соревнования параметр решено оставить.

### Вывод
В результате преобразований и в сравнении с наивной моделью мы видим значительные улучшения предсказательной способности нашей модели с учетом небольшого количества имеющихся данных. В 68% случаев наша модель верно определяет класс клиента.

### Работа в команде
Данный проект готовился в команде из двух участников. Оба участника команды внесли одинаковый вклад в финальный результат команды. Для отработки навыков каждый из членов команды занимался:
- разведывательным анализом данных (очистка данных, работа с выбросами, визуализация)
- генерация новых признаков, отбор значимых признаков
- написание функций и проведение экспериментов для улучшения качества модели (включая oversampling, undersampling, deature selection, stratified shuffle split, etc.)
- подбор и настройка гиперпараметров для модели
- оформление презентационной работы
