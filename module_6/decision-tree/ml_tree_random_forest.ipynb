{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0603df9",
   "metadata": {},
   "source": [
    "# Случайный лес\n",
    "\n",
    "АЛГОРИТМ ПОСТРОЕНИЯ СЛУЧАЙНОГО ЛЕСА, СОСТОЯЩЕГО ИЗ ДЕРЕВЬЕВ\n",
    "\n",
    "Для каждого:\n",
    "\n",
    "- сгенерировать выборку с помощью бутстрэпа;\n",
    "- построить решающее дерево по выборке: по заданному критерию мы выбираем лучший признак, делаем разбиение в дереве по нему и так до исчерпания выборки → дерево строится, пока в каждом листе не более объектов или пока не достигнем определенной высоты дерева → при каждом разбиении сначала выбирается несколько случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них.\n",
    "\n",
    "Итоговый классификатор $a(x) = \\frac{1}{N} \\sum_{i=1}^{N}{b_{i} (x)}$, иными словами — для задачи классификации мы выбираем решение голосованием по большинству, а в задаче регрессии — средним.\n",
    "\n",
    "Рекомендуется в задачах классификации брать $m = \\sqrt{(n)}$, а в задачах регрессии — $m = \\frac{n}{3}$, где n — число признаков. Также рекомендуется в задачах классификации строить каждое дерево до тех пор, пока в каждом листе не окажется по одному объекту, а в задачах регрессии — пока в каждом листе не окажется по пять объектов.\n",
    "\n",
    "Таким образом, случайный лес — это бэггинг над решающими деревьями, при обучении которых для каждого разбиения признаки выбираются из некоторого случайного подмножества признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634bd61",
   "metadata": {},
   "source": [
    "## РЕАЛИЗАЦИЯ НА PYTHON  И ПОДБОР ПАРАМЕТРОВ\n",
    "\n",
    "Теперь обучим случайный лес на простых данных и посмотрим, как можно подбирать параметры случайного леса для достижения наилучшего качества модели.\n",
    "\n",
    "> Потренируемся на данных, по которым мы будем предсказывать погоду. Датасет можно найти [здесь temps_extended.csv](./../data/temps_extended.csv).\n",
    "\n",
    "Откроем его, удалим признаки, не относящиеся к предсказанию (от дня недели, например, или от года погода не зависит), разделим на тестовую и обучающуюся выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53965ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, datasets, metrics, tree, ensemble, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e6fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('./../data/temps_extended.csv')\n",
    "y = weather['actual']\n",
    "X = weather.drop(['actual', 'weekday', 'month', 'day', 'year'], axis=1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267b1ca",
   "metadata": {},
   "source": [
    "Попробуем подобрать гиперпараметры таким образом, чтобы получить оптимальный результат.\n",
    "\n",
    "Если мы запускаем случайный лес без настройки параметров, то по умолчанию они следующие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6e4f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры по умолчанию:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pprint import pprint\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "# Look at parameters used by our current forest\n",
    "print('Параметры по умолчанию:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a407acb3",
   "metadata": {},
   "source": [
    "Попробуем подбирать разные значения для некоторых параметров. Для перебора вариантов возьмем следующие параметры:\n",
    "\n",
    "- n_estimators \n",
    "- max_features \n",
    "- max_depth \n",
    "- min_samples_split \n",
    "- min_samples_leaf\n",
    "- bootstrap\n",
    "\n",
    "Мы можем сами указать, какие значения гиперпараметров надо перебрать.\n",
    "\n",
    "Зададим сетку гиперпараметров, которые будут перебираться:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22e286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5190787e",
   "metadata": {},
   "source": [
    "Обучим наш лес:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2814aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=100,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71896f29",
   "metadata": {},
   "source": [
    "Давайте посмотрим, какие гиперпараметры нам предлагают как оптимальные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528a1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbd53d4",
   "metadata": {},
   "source": [
    "## Задача 1\n",
    "\n",
    "Обучите случайный лес с предустановленными параметрами и теми параметрами, которые мы отобрали как оптимальные. В обоих вариантах поставьте `random_state=42`. Какое улучшение MSE дала подстановка отобранных гиперпараметров? Ответ округлите до одного знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875277cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(metrics.mean_squared_error(y_test, rf_random.predict(X_test)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05bd580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(random_state=42)\n",
    "rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d4aa15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(metrics.mean_squared_error(y_test, rf2.predict(X_test)) -\n",
    "         metrics.mean_squared_error(y_test, rf_random.predict(X_test)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6bb6c",
   "metadata": {},
   "source": [
    "## Практика\n",
    "\n",
    "- Загрузите датасет digits с помощью функции **load_digits** из **sklearn.datasets** и подготовьте матрицу признаков **X** и ответы на обучающей выборке **y** (вам потребуются поля data и target в объекте, который возвращает load_digits). \n",
    "\n",
    "- Информацию о датасете вы можете получить, обратившись к полю DESCR у возвращаемого объекта load_digits. Нам предстоит решать задачу классификации изображений с цифрами по численным признакам.\n",
    "\n",
    "- Для оценки качества мы будем использовать **cross_val_score** из **sklearn.model_selection** с параметром cv=10. Эта функция реализует k-fold cross validation c **k** равным значению параметра **cv**. Предлагается использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и *k=5*. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет *k* чисел — качество в каждом из *k* экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
    "\n",
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадёт в диапазон, заданный для правильных ответов — в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "\n",
    "Чтобы ускорить вычисление cross_val_score, следует попробовать использовать параметр n_jobs. Число, которое вы подаёте в качестве этого параметра, соответствует количеству потоков вашего процессора, которое будет задействовано в вычислении. Если указать n_jobs = -1, тогда будут задействовано максимальное число потоков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "84871c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcc0d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_df = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acfa3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits_df.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80c35a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = digits_df['data'], digits_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dfc7727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_accuracy(clf, X, y, cv=5):\n",
    "    return np.round(\n",
    "        model_selection.cross_val_score(clf, X, y, cv=cv, scoring='accuracy', n_jobs=-1).mean(),\n",
    "        3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f4d8e",
   "metadata": {},
   "source": [
    "#### Задание 1\n",
    "\n",
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score.\n",
    "\n",
    "Эту величину введите в поле для ответа (ваше значение должно попасть в заданный интервал)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24eafc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des_tree = tree.DecisionTreeClassifier()\n",
    "des_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95d0642b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " estimate_accuracy(des_tree, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f57e8",
   "metadata": {},
   "source": [
    "#### Задание 2\n",
    "\n",
    "Теперь давайте обучим BaggingClassifier на основе DecisionTreeClassifier. Из sklearn.ensemble импортируйте BaggingClassifier, все параметры задайте по умолчанию. Нужно изменить только количество базовых моделей, задав его равным .\n",
    "\n",
    "В поле для ответа введите качество бэггинга на нашем датасете (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Подумайте, какие выводы можно сделать из соотношения качества одиночного дерева и бэггинга деревьев?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa2c2591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf = ensemble.BaggingClassifier(tree.DecisionTreeClassifier(), n_estimators=100)\n",
    "bagging_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "032e541f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_accuracy(bagging_clf, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20338f16",
   "metadata": {},
   "source": [
    "#### Задание 3\n",
    "\n",
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на $\\sqrt{d}$ случайных признаках.\n",
    "\n",
    "В поле для ответа введите качество работы получившегося классификатора (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "Корень из числа признаков — часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три, log d тоже имеет место быть. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков, добиваясь лучшего качества на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60e51cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_len = len(digits_df.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bc033489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(), max_features=8,\n",
       "                  n_estimators=100)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf = ensemble.BaggingClassifier(\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    max_features=int(np.sqrt(features_len))\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f1ba8660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.928"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_accuracy(bagging_clf, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63591075",
   "metadata": {},
   "source": [
    "#### Задание 4\n",
    "\n",
    "В предыдущем пункте мы выбирали подмножество один раз для каждого очередного дерева. Следующим нашим шагом будет построение бэггинга на основе деревьев, которые выбирают случайное подможество признаков для каждой вершины дерева.\n",
    "\n",
    "Для этого нам потребуется перенести отвечающий за это параметр из BaggingClassifier в DecisionTreeClassifier. Для этого вам из документации нужно выяснить, какой параметр DecisionTreeClassifier за это отвечает.\n",
    "\n",
    "В поле для ответа введите значение этого параметра (ваше значение должно попасть в заданный интервал).\n",
    "\n",
    "По-прежнему сэмплируем sqrt(d) признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b5cffdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_features=8),\n",
       "                  n_estimators=100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_clf = ensemble.BaggingClassifier(\n",
    "    tree.DecisionTreeClassifier(max_features=int(np.sqrt(features_len))),\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "00dc7b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_accuracy(bagging_clf, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4715434",
   "metadata": {},
   "source": [
    "Полученный в задании 4 классификатор — бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0fb17dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    max_features=int(np.sqrt(features_len)),\n",
    "    max_depth=30\n",
    ")\n",
    "\n",
    "estimate_accuracy(random_forest, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc4b53",
   "metadata": {},
   "source": [
    "- При очень маленьком числе деревьев (5, 10, 15) случайный лес работает хуже, чем при большем числе деревьев.\n",
    "- С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "- При большом количестве признаков (для данного датасета - 40-50) качество классификации становится хуже, чем при малом количестве признаков (10-15). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "- При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, так как из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa63cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
