{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bbed7e",
   "metadata": {},
   "source": [
    "# БЭГГИНГ (BAGGING, BOOTSTRAP AGGREGATING)\n",
    "\n",
    "<span style=\"font-family:Papyrus; font-size:1.5em;\">АНСАМБЛЬ МОДЕЛЕЙ (БЭГГИНГ)</span>\n",
    "\n",
    "Bagging — это параллельный способ построения ансамбля. Коротко о способе построения:\n",
    "\n",
    "- Обучающая выборка сэмплируется  раз с помощью bootstrap (выбор с возвращением).\n",
    "- На каждом сэмпле обучается отдельная базовая модель.\n",
    "- Ответы моделей усредняются (возможно, с весами).\n",
    "\n",
    "Необходимость бэггинга может возникнуть тогда, когда вы уже нашли хорошую модель, и никак больше не можете повысить ее качество. В этом случае можно перейти к более продвинутой истории: использовать не одну модель (пусть и очень хорошую!), а ансамбли моделей. Под термином ансамбли понимается ряд продвинутых техник машинного обучения, о которых мы поговорим далее.\n",
    "\n",
    "> ## ПРИМЕР: ТЕОРЕМА КОНДОРСА\n",
    "Проиллюстрируем идею ансамблей на известном примере — теореме Кондорса о жюри присяжных, которая датируется аж 1784 годом!\n",
    ">\n",
    "> Представим, что у нас есть несколько членов жюри, мнение каждого из них независимо от мнения других. Мы не знаем, какая вероятность принятия верного решения у каждого члена жюри. Однако мы понимаем, что если вероятность принять правильное решение у какого-то члена жюри больше, чем , то и общая вероятность принять верное решение возрастает. И наоборот, если вероятность принять правильное решение у какого-то члена жюри меньше, чем , то общая вероятность принять верное решение падает.\n",
    "\n",
    "## БЭГГИНГ (BAGGING, BOOTSTRAP AGGREGATING)\n",
    "\n",
    "Цель бэггинга заключается в том, чтобы создать ансамбль из нескольких моделей. Такая ансамблевая модель будет надежнее, чем составляющие ее части.\n",
    "\n",
    "В основе бэггинга лежит статистический метод, который называется бутстрэпом (bootstrap). Идея бутстрэпа заключается в генерации выборок размера **B** (так называемых бутстрэп-выборок) из исходного датасета размера **N** путем случайного выбора элементов с повторениями в каждом из наблюдений **B**.\n",
    "\n",
    "Рассмотрим идею бутстрэпа на элементарном примере.\n",
    "\n",
    "Пусть у нас есть выборка из **12** элементов. Тогда мы можем из нее выбирать различные выборки из нового количества элементов (в данном случае из 5). При этом, если мы использовали какой-то объект, то мы можем использовать его снова. Таким образом, мы можем из одной выборки получить множество новых.\n",
    "\n",
    "![bagging](./../img/bagging1.png)\n",
    "\n",
    "При некотором приближении можно считать, что получающиеся выборки являются независимыми и репрезентативными.\n",
    "\n",
    "Такие бутстрэп-выборки часто используются для оценки различных статистических показателей (например, разброса или доверительного интервала). Если вычислять статистические оценки на нескольких независимых выборках, то мы можем оценить их разброс. Поиск большого количества независимых выборок сложен в силу того, что для этого требуется слишком много данных. Поэтому мы используем бутстрэп, чтобы создать несколько выборок, которые являются независимыми и репрезентативными (но, опять же, стоит отметить, что такими их можно считать только при нескольких допущениях).\n",
    "\n",
    "Перейдем к понятию бэггинга. При построении моделей всегда присутствует вероятность, что при обучении на других данных мы получили бы другие результаты. Для того, чтобы нивелировать такую вероятность, можно использовать бэггинг. \n",
    "\n",
    "Его идея состоит в том, что мы берем несколько независимых моделей и усредняем полученные по ним результаты. Таким образом, мы получаем модель, имеющую меньший разброс, так как при ее построении мы учли несколько моделей. Как уже было сказано, в реальности получить много независимых выборок слишком сложно в силу того, что найти столько данных обычно не представляется возможным. Поэтому мы используем бутстрэп-выборки. \n",
    "\n",
    "> Важно отметить, что при бэггинге размер каждой бутстрэп-выборки должен совпадать с размером исходной выборки.\n",
    "\n",
    "## RANDOM SUBSPACES (RSS)\n",
    "\n",
    "Для построения набора различных моделей используется также метод выбора случайных подвыборок признаков Random Subspaces. Метод обеспечивает устойчивость алгоритма к набору доступных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49af81f",
   "metadata": {},
   "source": [
    "## ЗАДАЧА О ВИНАХ\n",
    "Реализуем бэггинг для деревьев решений. Для тренировки будем использовать датасет о винах. \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./../img/wine.png\" style=\"width: 300px;\"/>\n",
    "</div>\n",
    "\n",
    "Датасет можно скачать [здесь winequality-red.csv](./../data).\n",
    "\n",
    "Для начала подготовим данные к классификации. Условно разделим вино на хорошее и нет. Хорошим вином будем называть вино, параметр quality которого не менее 6.\n",
    "\n",
    "Теперь сравним несколько методов классификации: логистическую регрессию, решающее дерево и бэггинг.\n",
    "\n",
    "Разбейте выборку на обучающую и тренировочную с параметрами `test_size=0.30, random_state=42`.\n",
    "\n",
    "Обучите два классификатора: логистическую регрессию (с дефолтными параметрами) и решающее дерево (`random_state=42`, максимальная глубина равна `10`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cdbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, datasets, metrics, tree, ensemble, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a06dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./../model_inspector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a06e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe88adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = pd.read_csv('./../data/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ff5784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>10.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.111</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.37</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.214</td>\n",
       "      <td>55.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.00369</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.77</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>8.7</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.415</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99623</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.089</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.99735</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.61</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.012</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.99064</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.39</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "416            10.6              0.48         0.64             2.2      0.111   \n",
       "1435           10.2              0.54         0.37            15.4      0.214   \n",
       "1372            8.7              0.78         0.51             1.7      0.415   \n",
       "959             8.0              0.59         0.05             2.0      0.089   \n",
       "836             6.7              0.28         0.28             2.4      0.012   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "416                   6.0                  20.0  0.99700  3.26       0.66   \n",
       "1435                 55.0                  95.0  1.00369  3.18       0.77   \n",
       "1372                 12.0                  66.0  0.99623  3.00       1.17   \n",
       "959                  12.0                  32.0  0.99735  3.36       0.61   \n",
       "836                  36.0                 100.0  0.99064  3.26       0.39   \n",
       "\n",
       "      alcohol  quality  \n",
       "416      11.7        6  \n",
       "1435      9.0        6  \n",
       "1372      9.2        5  \n",
       "959      10.0        5  \n",
       "836      11.7        7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae09f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62904724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test data\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    wine_df.drop(columns=['quality']), \n",
    "    wine_df['quality'], \n",
    "    test_size=0.3, \n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41941715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_clf = linear_model.LogisticRegression()\n",
    "log_reg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55876f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_clf = tree.DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=10)\n",
    "dec_tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0cd3e6",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "\n",
    "Введите значение f1 score для классификатора, который показал наилучшее значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc99470",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5546b4e2ebb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlog_reg_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_reg_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_reg_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \"\"\"\n\u001b[0;32m-> 1071\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1072\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \"\"\"\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1196\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1465\u001b[0m                                     pos_label)\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[1;32m   1295\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "log_reg_predictions = log_reg_clf.predict(X_test)\n",
    "np.round(metrics.f1_score(y_test, log_reg_predictions), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree_clf_predictions = dec_tree_clf.predict(X_test)\n",
    "np.round(metrics.f1_score(y_test, dec_tree_clf_predictions), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f1913",
   "metadata": {},
   "source": [
    "### Задача 2\n",
    "\n",
    "Обучите модель с использование бэггинга (функция BaggingClassifier с `random_state=42`, разделение выборки на обучающую и тренировочную с параметрами `test_size=0.30, random_state=42`) для алгоритма, показавшего лучшее качество, определите количество моделей `1500`. Вычислите новое значение `f1-score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bagging_clf = ensemble.BaggingClassifier(dec_tree_clf, random_state=RANDOM_STATE, n_estimators=1500)\n",
    "tree_bagging_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_bagging_clf_predictions = tree_bagging_clf.predict(X_test)\n",
    "np.round(metrics.f1_score(y_test, tree_bagging_clf_predictions, average='weighted'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9404329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
